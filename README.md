# Video Analytic Bot

## Конфигурация

Для конфигурации приложения используется файл `.env`, скопируйте файл [`.env.example`](.env.example) и переименуете его в `.env`, укажите в нем токен для бота в переменную `TGM_BOT_TOKEN`, а также ключ для доступа к *OpenAI API* в переменную `OPENAI_API_KEY`.

## Запуск с помощью *Docker*

> [!WARNING]
> *Docker* должен быть установлен на вашем устройстве!

Для запуска приложения с помощью *Docker* введите следующую команду:
```sh
docker compose up -d
```

Бот будет доступен в *Telegram*.

## Запуск локально

> [!WARNING]
> *Python* версии не ниже 3.13 должен быть установлен на вашем устройстве!

### Установка зависимостей

Если вы используете *uv*, введите следующую команды:
```sh
uv sync --locked
source .venv/bin/activate
``` 
Если вы используете *poetry*, введите следующие команды:
```sh
poetry install --no-root
eval $(poetry env activate)
``` 
Иначе используйте *pip*:
```sh
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### Запуск

> [!WARNING]
> Приложение расчитано на использование *PostgreSQL*, если хотите воспользоваться другой СУБД, установите соответствующие зависимости и измените движок в файле [`src/settings.py`](src/settings.py).  
> Перед запуском убедитесь, что данные для подключения к базе данных в файле `.env` соответствуют вашей локально запущенной базе данных!

Перед первым запуском проведите миграции базы данных:
```sh
alembic upgrade head
```

Запустите приложение локально с помощью следующей команды:
```sh
python main.py
```

Бот будет доступен в *Telegram*.

## Популяция базы данных

Для заполнения базы данных данными из *json*-файла, если приложение запущено в *Docker*, выполните следующую команду:

```sh
docker exec -i analytic_app uv run main.py --parse < <путь к файлу>
```

Если приложение может быть запущено локально:

```sh
python main.py --parse < <путь к файлу>
```

## Архитектура

Основной хэндлер сообщений находится в файле [`user.py`](src/handlers/user.py), сервисы передаются в хэндлер через [*middleware*](src/middlewares). [`LLMService`](src/services/llm_service.py) отвечает за отправку исходных сообщений пользователя в *LLM* через *OpenAI API*. [`DBService`](src/services/db_service.py) отвечает за отправку сгенерированных *SQL*-запросов в базу данных.  
Промпт для *LLM* расположен в файле [`prompts.py`](src/prompts.py). Схема данных описывается с помощью *SQL*-схемы.
